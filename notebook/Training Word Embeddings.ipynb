{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e87cc33",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80e4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data.txt\",\"r\")\n",
    "data = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff02bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The future king is the prince\\n',\n",
       " 'Daughter is the princess\\n',\n",
       " 'Son is the prince\\n',\n",
       " 'Only a man can be a king\\n',\n",
       " 'Only a woman can be a queen\\n',\n",
       " 'The princess will be a queen\\n',\n",
       " 'The prince is a strong man\\n',\n",
       " 'The princess is a beautiful woman\\n',\n",
       " 'Prince is only a boy now\\n',\n",
       " 'Prince will be king\\n',\n",
       " 'A boy will be a man']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7ff6a",
   "metadata": {},
   "source": [
    "#### Removing '\\n' from the end of every sentence and convert the sentence into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798b4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the future king is the prince', 'daughter is the princess', 'son is the prince', 'only a man can be a king', 'only a woman can be a queen', 'the princess will be a queen', 'the prince is a strong man', 'the princess is a beautiful woman', 'prince is only a boy now', 'prince will be king', 'a boy will be a man']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i] = data[i].lower().replace('\\n','')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da267729",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f084080",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'is', 'will', 'be', 'a', 'only', 'can', 'their', 'now', 'and', 'at', 'it']\n",
    "\n",
    "filtered_data = []\n",
    "for sentence in data:\n",
    "    temp = []\n",
    "    for word in sentence.split():\n",
    "        if word not in stopwords:\n",
    "            temp.append(word)\n",
    "    filtered_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d778d3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['future', 'king', 'prince'],\n",
       " ['daughter', 'princess'],\n",
       " ['son', 'prince'],\n",
       " ['man', 'king'],\n",
       " ['woman', 'queen'],\n",
       " ['princess', 'queen'],\n",
       " ['prince', 'strong', 'man'],\n",
       " ['princess', 'beautiful', 'woman'],\n",
       " ['prince', 'boy'],\n",
       " ['prince', 'king'],\n",
       " ['boy', 'man']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e375e",
   "metadata": {},
   "source": [
    "#### Creating Biagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a731b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "for word_list in filtered_data:\n",
    "    for i in range(len(word_list) -1):\n",
    "        for j in range(i+1, len(word_list)):\n",
    "            bigrams.append([word_list[i],word_list[j]])\n",
    "            bigrams.append([word_list[j],word_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ccf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['future', 'king'],\n",
       " ['king', 'future'],\n",
       " ['future', 'prince'],\n",
       " ['prince', 'future'],\n",
       " ['king', 'prince'],\n",
       " ['prince', 'king'],\n",
       " ['daughter', 'princess'],\n",
       " ['princess', 'daughter'],\n",
       " ['son', 'prince'],\n",
       " ['prince', 'son'],\n",
       " ['man', 'king'],\n",
       " ['king', 'man'],\n",
       " ['woman', 'queen'],\n",
       " ['queen', 'woman'],\n",
       " ['princess', 'queen'],\n",
       " ['queen', 'princess'],\n",
       " ['prince', 'strong'],\n",
       " ['strong', 'prince'],\n",
       " ['prince', 'man'],\n",
       " ['man', 'prince'],\n",
       " ['strong', 'man'],\n",
       " ['man', 'strong'],\n",
       " ['princess', 'beautiful'],\n",
       " ['beautiful', 'princess'],\n",
       " ['princess', 'woman'],\n",
       " ['woman', 'princess'],\n",
       " ['beautiful', 'woman'],\n",
       " ['woman', 'beautiful'],\n",
       " ['prince', 'boy'],\n",
       " ['boy', 'prince'],\n",
       " ['prince', 'king'],\n",
       " ['king', 'prince'],\n",
       " ['boy', 'man'],\n",
       " ['man', 'boy']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c5f31",
   "metadata": {},
   "source": [
    "#### Get Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c581939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words are: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['beautiful',\n",
       " 'boy',\n",
       " 'daughter',\n",
       " 'future',\n",
       " 'king',\n",
       " 'man',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'son',\n",
       " 'strong',\n",
       " 'woman']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "for bigram in bigrams:\n",
    "    all_words.extend(bigram)\n",
    "\n",
    "all_words = list(set(all_words))\n",
    "all_words.sort()\n",
    "print(\"Total number of unique words are:\", len(all_words))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eaa906",
   "metadata": {},
   "source": [
    "#### Creating dictionary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d1db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beautiful': 0, 'boy': 1, 'daughter': 2, 'future': 3, 'king': 4, 'man': 5, 'prince': 6, 'princess': 7, 'queen': 8, 'son': 9, 'strong': 10, 'woman': 11}\n"
     ]
    }
   ],
   "source": [
    "words_dict = {}\n",
    "\n",
    "counter = 0\n",
    "for word in all_words:\n",
    "    words_dict[word] = counter\n",
    "    counter +=1\n",
    "print(words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c32d6",
   "metadata": {},
   "source": [
    "#### Performing one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05bf99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1374bfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beautiful': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'boy': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'daughter': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'future': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'king': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'man': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'prince': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'princess': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'queen': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " 'son': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'strong': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 'woman': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_data = np.zeros((len(all_words), len(all_words)))\n",
    "for i in range(len(all_words)):\n",
    "    onehot_data[i][i] = 1\n",
    "    \n",
    "onehot_dict = {}\n",
    "counter = 0\n",
    "for word in all_words:\n",
    "    onehot_dict[word] = onehot_data[counter]\n",
    "    counter+=1\n",
    "onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ea2e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "boy : [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "daughter : [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "future : [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "king : [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "man : [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "prince : [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "princess : [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "queen : [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "son : [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "strong : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "woman : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for word in onehot_dict:\n",
    "    print(word, \":\", onehot_dict[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bab8cd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])]\n",
      "[array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for bi in bigrams:\n",
    "    X.append(onehot_dict[bi[0]])\n",
    "    Y.append(onehot_dict[bi[1]])\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43679bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "embed_size = 2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(embed_size, activation='linear'),\n",
    "    Dense(Y.shape[1], activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be74b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs = 1000, batch_size = 256, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928233f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()[0]\n",
    "\n",
    "word_embeddings = {}\n",
    "for word in all_words:\n",
    "    word_embeddings[word] = weights[words_dict[word]]\n",
    "\n",
    "# print(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76118256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize = (10, 10))\n",
    "for word in list(words_dict.keys()):\n",
    "    coord = word_embeddings.get(word)\n",
    "    plt.scatter(coord[0], coord[1])\n",
    "    plt.annotate(word, (coord[0], coord[1]))\n",
    "\n",
    "plt.savefig('img.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban",
   "language": "python",
   "name": "urban"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
